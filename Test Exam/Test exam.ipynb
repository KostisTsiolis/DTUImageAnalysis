{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-19T14:54:44.416269Z",
     "start_time": "2025-05-19T14:54:10.001631Z"
    }
   },
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib qt\n",
    "# Load dataset\n",
    "breast = load_breast_cancer()\n",
    "x = breast.data\n",
    "target = breast.target\n",
    "\n",
    "# Standardize the data (zero mean, unit variance)\n",
    "x_mean = np.mean(x, axis=0)\n",
    "x_std = np.std(x, axis=0)\n",
    "x_scaled = (x - x_mean) / x_std\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T14:54:47.672895Z",
     "start_time": "2025-05-19T14:54:47.660177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compute covariance matrix\n",
    "cov_matrix = np.cov(x_scaled.T)\n",
    "\n",
    "# Compute eigenvalues and eigenvectors\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "# Sort eigenvectors by decreasing eigenvalue magnitude\n",
    "sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "eigenvectors_sorted = eigenvectors[:, sorted_indices]\n",
    "eigenvalues_sorted = eigenvalues[sorted_indices]\n",
    "\n",
    "# Project data onto the first two principal components\n",
    "pca_projection = x_scaled @ eigenvectors_sorted[:, :2]\n"
   ],
   "id": "1c16a8bfbf60ff28",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T14:55:28.142896Z",
     "start_time": "2025-05-19T14:55:28.018464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(pca_projection[:, 0], pca_projection[:, 1],\n",
    "                      c=target, cmap='bwr', alpha=0.7, edgecolors='k')\n",
    "plt.xlabel(\"First Principal Component\")\n",
    "plt.ylabel(\"Second Principal Component\")\n",
    "plt.title(\"Breast Cancer Dataset - PCA Projection\")\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=[\"Cancer (0)\", \"No Cancer (1)\"])\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "8f70bca81af50a9b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T14:56:33.834904Z",
     "start_time": "2025-05-19T14:56:33.822675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Assume pca_projection is already computed and has shape [n_samples, 2]\n",
    "# Extract the first principal component values\n",
    "pc1 = pca_projection[:, 0]\n",
    "\n",
    "# Compute mean projections for each class\n",
    "mean_pc1_negative = np.mean(pc1[target == 0])  # Cancer patients\n",
    "mean_pc1_positive = np.mean(pc1[target == 1])  # Non-cancer patients\n",
    "\n",
    "print(f\"Mean PC1 projection (negative, cancer): {mean_pc1_negative:.4f}\")\n",
    "print(f\"Mean PC1 projection (positive, no cancer): {mean_pc1_positive:.4f}\")\n"
   ],
   "id": "bfa1e407fb23889e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean PC1 projection (negative, cancer): 3.7148\n",
      "Mean PC1 projection (positive, no cancer): -2.2060\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T14:57:32.413467Z",
     "start_time": "2025-05-19T14:57:32.392043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Assume pca_projection and target are already defined\n",
    "pc1 = pca_projection[:, 0]\n",
    "\n",
    "# Apply rule: predict 1 if PC1 < 0 (no cancer), else 0 (cancer)\n",
    "predicted = np.where(pc1 < 0, 1, 0)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(predicted == target)\n",
    "print(f\"Classifier accuracy: {accuracy:.4f}\")\n"
   ],
   "id": "ae3e39c1f4aadc3e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier accuracy: 0.9156\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T14:58:19.025690Z",
     "start_time": "2025-05-19T14:58:19.008707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Assume pca_projection is already computed\n",
    "pc1 = pca_projection[:, 0]\n",
    "\n",
    "# Classify as positive (no cancer, label 1) if PC1 < 0\n",
    "predicted = np.where(pc1 < 0, 1, 0)\n",
    "\n",
    "# Count how many samples are classified as positive\n",
    "num_positive = np.sum(predicted == 1)\n",
    "\n",
    "print(f\"Number of samples classified as positive (no cancer): {num_positive}\")\n"
   ],
   "id": "26536d25dc355232",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples classified as positive (no cancer): 349\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T14:59:05.818537Z",
     "start_time": "2025-05-19T14:59:05.756341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load the dataset\n",
    "breast = load_breast_cancer()\n",
    "x = breast.data\n",
    "target = breast.target\n",
    "\n",
    "# Get shape\n",
    "n_samples, n_features = x.shape\n",
    "\n",
    "print(f\"Number of observations (patients): {n_samples}\")\n",
    "print(f\"Number of features per observation: {n_features}\")\n"
   ],
   "id": "6f3c486d247286d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations (patients): 569\n",
      "Number of features per observation: 30\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T15:02:34.323232Z",
     "start_time": "2025-05-19T15:02:34.279274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "roi_D = np.loadtxt(\"D_Cubes.txt\")\n",
    "roi_E = np.loadtxt(\"E_Cubes.txt\")\n",
    "\n",
    "# Estimate parameters\n",
    "mu_D, std_D = np.mean(roi_D), np.std(roi_D)\n",
    "mu_E, std_E = np.mean(roi_E), np.std(roi_E)\n",
    "\n",
    "# Search for intersection\n",
    "x_range = np.linspace(min(mu_D, mu_E) - 3*max(std_D, std_E),\n",
    "                      max(mu_D, mu_E) + 3*max(std_D, std_E), 1000)\n",
    "pdf_D = norm.pdf(x_range, mu_D, std_D)\n",
    "pdf_E = norm.pdf(x_range, mu_E, std_E)\n",
    "\n",
    "# Find intersection point (minimum absolute difference)\n",
    "diff = np.abs(pdf_D - pdf_E)\n",
    "threshold_index = np.argmin(diff)\n",
    "optimal_threshold = x_range[threshold_index]\n",
    "\n",
    "# Output result\n",
    "print(f\"Optimal threshold between ROI D and ROI E: {optimal_threshold:.2f}\")\n",
    "\n",
    "# Optional: plot\n",
    "plt.plot(x_range, pdf_D, label='ROI D')\n",
    "plt.plot(x_range, pdf_E, label='ROI E')\n",
    "plt.axvline(optimal_threshold, color='red', linestyle='--', label=f'Threshold = {optimal_threshold:.2f}')\n",
    "plt.title(\"Gaussian PDFs and Optimal Threshold\")\n",
    "plt.xlabel(\"Intensity\")\n",
    "plt.ylabel(\"Probability Density\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "id": "dd7dcdac29e9df56",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold between ROI D and ROI E: -8.57\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T15:08:24.955844Z",
     "start_time": "2025-05-19T15:08:24.847471Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cost function\n",
    "def cost(x1, x2):\n",
    "    return 7 * x1**2 + x1 * x2 + 3 * x2**2\n",
    "\n",
    "# Gradient of the cost function\n",
    "def gradient(x1, x2):\n",
    "    dc_dx1 = 14 * x1 + x2\n",
    "    dc_dx2 = x1 + 6 * x2\n",
    "    return np.array([dc_dx1, dc_dx2])\n",
    "\n",
    "# Parameters\n",
    "alpha = 0.1              # step size\n",
    "iterations = 26\n",
    "x_start = np.array([2.0, 2.0])  # Starting point (green dot)\n",
    "x_vals = [x_start]\n",
    "\n",
    "# Perform gradient descent\n",
    "x = x_start\n",
    "for _ in range(iterations):\n",
    "    grad = gradient(x[0], x[1])\n",
    "    x = x - alpha * grad\n",
    "    x_vals.append(x)\n",
    "\n",
    "x_vals = np.array(x_vals)\n",
    "\n",
    "# Plot cost surface contours\n",
    "x1_grid, x2_grid = np.meshgrid(np.linspace(-4, 4, 200), np.linspace(-4, 4, 200))\n",
    "c_grid = cost(x1_grid, x2_grid)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.contour(x1_grid, x2_grid, c_grid, levels=50, cmap='viridis')\n",
    "plt.plot(x_vals[:, 0], x_vals[:, 1], 'r-o', label=\"Gradient Descent Path\")\n",
    "plt.scatter(x_start[0], x_start[1], color='green', s=100, label='Start Point')\n",
    "plt.title(\"Gradient Descent in 2D Parameter Space\")\n",
    "plt.xlabel(\"$x_1$\")\n",
    "plt.ylabel(\"$x_2$\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.axis('equal')\n",
    "plt.show()\n"
   ],
   "id": "20e9ea0780651b26",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T15:10:12.406754Z",
     "start_time": "2025-05-19T15:10:12.377315Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# Cost function\n",
    "def cost(x1, x2):\n",
    "    return 7 * x1**2 + x1 * x2 + 3 * x2**2\n",
    "\n",
    "# Gradient of the cost function\n",
    "def gradient(x1, x2):\n",
    "    dc_dx1 = 14 * x1 + x2\n",
    "    dc_dx2 = x1 + 6 * x2\n",
    "    return np.array([dc_dx1, dc_dx2])\n",
    "\n",
    "# Parameters\n",
    "alpha = 0.1\n",
    "x = np.array([2.0, 2.0])  # Start point\n",
    "threshold = 2.0\n",
    "\n",
    "# Run gradient descent and monitor cost\n",
    "for i in range(1000):  # Max 1000 iterations for safety\n",
    "    c = cost(x[0], x[1])\n",
    "    if c < threshold:\n",
    "        print(f\"Cost dropped below {threshold} after {i} iterations (c = {c:.4f})\")\n",
    "        break\n",
    "    grad = gradient(x[0], x[1])\n",
    "    x = x - alpha * grad\n",
    "else:\n",
    "    print(\"Cost did not drop below threshold within 1000 iterations.\")\n"
   ],
   "id": "83cdf902151446cf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost dropped below 2.0 after 2 iterations (c = 1.2716)\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T15:13:47.579830Z",
     "start_time": "2025-05-19T15:13:47.510701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# Load training data\n",
    "data = np.loadtxt(\"traffic_train.txt\", delimiter=\",\")\n",
    "\n",
    "# Split into features and classes\n",
    "density = data[:, 0]\n",
    "speed = data[:, 1]\n",
    "weather = data[:, 2]  # not used for this plot\n",
    "\n",
    "# Class labels based on row order\n",
    "# First 140 → Class 1 (morning), Next 140 → Class 2 (afternoon)\n",
    "class1_density = density[:100]\n",
    "class1_speed = speed[:100]\n",
    "class2_density = density[140:240]\n",
    "class2_speed = speed[140:240]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(class1_density, class1_speed, c='green', label=\"Morning Traffic (Class 1)\")\n",
    "plt.scatter(class2_density, class2_speed, c='blue', label=\"Afternoon Traffic (Class 2)\")\n",
    "plt.xlabel(\"Density (cars)\")\n",
    "plt.ylabel(\"Speed (km/h)\")\n",
    "plt.title(\"Traffic Training Data (First 100 Samples per Class)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "id": "59a56a11f4700a1c",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T15:15:32.738991Z",
     "start_time": "2025-05-19T15:15:32.693244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# Load training data\n",
    "train_data = np.loadtxt(\"traffic_train.txt\", delimiter=\",\")\n",
    "X_train = train_data[:, :2]  # density and speed\n",
    "y_train = np.array([0]*140 + [1]*140)  # 0 = morning, 1 = afternoon\n",
    "\n",
    "# Train LDA model\n",
    "lda = LDA()\n",
    "lda.fit(X_train, y_train)\n",
    "\n",
    "# Load test data\n",
    "test_data = np.loadtxt(\"traffic_test.txt\", delimiter=\",\")\n",
    "X_test = test_data[:, :2]\n",
    "y_test = np.array([0]*60 + [1]*60)\n",
    "\n",
    "# Predict class labels\n",
    "y_pred = lda.predict(X_test)\n",
    "\n",
    "# Count misclassified afternoon samples as morning\n",
    "afternoon_indices = np.arange(60, 120)\n",
    "afternoon_misclassified = np.sum(y_pred[afternoon_indices] == 0)\n",
    "\n",
    "print(f\"Number of afternoon samples classified as morning (traffic jams): {afternoon_misclassified}\")\n"
   ],
   "id": "c0587b01a1e61b14",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of afternoon samples classified as morning (traffic jams): 9\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T15:16:30.163707Z",
     "start_time": "2025-05-19T15:16:30.152270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the training data\n",
    "data = np.loadtxt(\"traffic_train.txt\", delimiter=\",\")\n",
    "\n",
    "# Extract weather column for morning samples (first 140)\n",
    "weather_morning = data[:140, 2]\n",
    "\n",
    "# Count how many mornings had rain (weather = 1)\n",
    "num_rainy_mornings = np.sum(weather_morning == 1)\n",
    "\n",
    "print(f\"Number of rainy mornings in the training set: {int(num_rainy_mornings)}\")\n"
   ],
   "id": "4470b0350d67cc3d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rainy mornings in the training set: 70\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T15:18:51.021052Z",
     "start_time": "2025-05-19T15:18:48.698027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from skimage import io\n",
    "\n",
    "# Load the images (they should be label masks)\n",
    "fixed = io.imread(\"LabelsFixedImg.png\")\n",
    "moving = io.imread(\"LabelsMovingImg.png\")\n",
    "\n",
    "# Get coordinates of landmarks (labels 1 to 5)\n",
    "coords_fixed = np.argwhere((fixed >= 1) & (fixed <= 5))\n",
    "coords_moving = np.argwhere((moving >= 1) & (moving <= 5))\n",
    "\n",
    "# Compute average landmark positions\n",
    "avg_fixed = np.mean(coords_fixed, axis=0)\n",
    "avg_moving = np.mean(coords_moving, axis=0)\n",
    "\n",
    "# Compute Euclidean distance\n",
    "distance = np.linalg.norm(avg_fixed - avg_moving)\n",
    "\n",
    "print(f\"Euclidean distance between average landmarks: {distance:.2f}\")\n"
   ],
   "id": "20809324ddafcbf7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distance between average landmarks: 7.28\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T15:23:02.855175Z",
     "start_time": "2025-05-19T15:23:02.741907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from skimage import io\n",
    "from skimage.morphology import binary_opening, disk\n",
    "from skimage.measure import label\n",
    "\n",
    "# Step 1: Load grayscale images\n",
    "img_x = io.imread(\"x_NisslStain_9-260.81.png\", as_gray=True)\n",
    "img_y = io.imread(\"y_NisslStain_9-260.81.png\", as_gray=True)\n",
    "\n",
    "# Step 2: Threshold the images at 30\n",
    "bin_x = img_x > 30\n",
    "bin_y = img_y > 30\n",
    "\n",
    "# Step 3: Apply morphological opening with disk structuring element of size 3\n",
    "opened_x = binary_opening(bin_x, disk(3))\n",
    "opened_y = binary_opening(bin_y, disk(3))\n",
    "\n",
    "# Step 4: Label connected components (BLOBs)\n",
    "label_x = label(opened_x)\n",
    "label_y = label(opened_y)\n",
    "\n",
    "# Step 5: Count BLOBs (ignore background = 0)\n",
    "num_cells_x = np.max(label_x)\n",
    "num_cells_y = np.max(label_y)\n",
    "\n",
    "# Step 6: Output results\n",
    "print(f\"Number of individual cells in x image: {num_cells_x}\")\n",
    "print(f\"Number of individual cells in y image: {num_cells_y}\")\n"
   ],
   "id": "bcce2e888d001652",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of individual cells in x image: 0\n",
      "Number of individual cells in y image: 0\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T15:25:37.433781Z",
     "start_time": "2025-05-19T15:25:37.186651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pydicom\n",
    "import numpy as np\n",
    "from skimage import morphology, measure\n",
    "from skimage.morphology import disk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Load DICOM image\n",
    "ds = pydicom.dcmread(\"1-189.dcm\")\n",
    "img = ds.pixel_array\n",
    "\n",
    "# Step 2: Thresholding between 100 and 250\n",
    "binary = (img >= 100) & (img <= 250)\n",
    "\n",
    "# Step 3: Label connected components\n",
    "label_img = measure.label(binary)\n",
    "\n",
    "# Step 4: Filter BLOBs by area and perimeter (kidneys expected to be moderate to large)\n",
    "region_props = measure.regionprops(label_img)\n",
    "\n",
    "# Define area and perimeter thresholds (tuned empirically or based on prior info)\n",
    "area_min = 300\n",
    "area_max = 2000\n",
    "perimeter_min = 80\n",
    "perimeter_max = 300\n",
    "\n",
    "# Create mask for valid kidney regions\n",
    "kidney_mask = np.zeros_like(binary, dtype=bool)\n",
    "for region in region_props:\n",
    "    if area_min <= region.area <= area_max and perimeter_min <= region.perimeter <= perimeter_max:\n",
    "        kidney_mask[label_img == region.label] = 1\n",
    "\n",
    "# Step 5: Morphological closing with disk radius 3\n",
    "kidney_closed = morphology.closing(kidney_mask, disk(3))\n",
    "\n",
    "# Step 6: Compute number of foreground pixels\n",
    "pixel_count = np.sum(kidney_closed)\n",
    "\n",
    "# Step 7: Convert to physical area (0.78 mm × 0.78 mm)\n",
    "pixel_area_mm2 = 0.78 * 0.78\n",
    "total_area_mm2 = pixel_count * pixel_area_mm2\n",
    "\n",
    "total_area_cm2 = total_area_mm2 / 100\n",
    "print(f\"Total kidney area after processing: {total_area_cm2:.2f} cm²\")\n",
    "\n"
   ],
   "id": "faa845c0db2bf08d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total kidney area after processing: 4.44 cm²\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T15:26:39.300785Z",
     "start_time": "2025-05-19T15:26:39.291292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 1: HU image (from DICOM)\n",
    "hu_img = ds.pixel_array  # HU values\n",
    "\n",
    "# Step 2: Apply mask to extract HU values inside the segmented kidneys\n",
    "kidney_hu_values = hu_img[kidney_closed]\n",
    "\n",
    "# Step 3: Compute median HU value\n",
    "median_hu = np.median(kidney_hu_values)\n",
    "\n",
    "print(f\"Median HU value in kidney regions: {median_hu:.2f}\")\n"
   ],
   "id": "4ab68c52ad3f160c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median HU value in kidney regions: 128.00\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T15:30:51.174638Z",
     "start_time": "2025-05-19T15:30:49.512116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from skimage import io\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# Load expert segmentation (binary image: 1 = kidney, 0 = background)\n",
    "expert_mask = io.imread(\"1-189.dcm\") > 0  # adjust filename as needed\n",
    "\n",
    "# Flatten both masks to 1D\n",
    "flat_expert = expert_mask.ravel()\n",
    "flat_ours = kidney_closed.ravel()  # from your morphological segmentation\n",
    "\n",
    "# Compute DICE score\n",
    "dice_score = 1 - distance.dice(flat_ours, flat_expert)\n",
    "\n",
    "print(f\"DICE score between your segmentation and expert: {dice_score:.4f}\")\n"
   ],
   "id": "50f67f374bc3ca4b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading DICOM (examining files): 36/36 files (100.0%)\n",
      "  Found 1 correct series.\n",
      "DICE score between your segmentation and expert: 0.0214\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T15:31:55.497641Z",
     "start_time": "2025-05-19T15:31:55.292937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from skimage.measure import regionprops, label\n",
    "\n",
    "# Assume 'binary' is your thresholded image between 100 and 250\n",
    "label_img = label(binary)\n",
    "\n",
    "# Measure all properties\n",
    "props = regionprops(label_img)\n",
    "\n",
    "# Loop to examine areas for blobs with perimeter in [400, 600]\n",
    "filtered_areas = []\n",
    "\n",
    "for region in props:\n",
    "    if 400 <= region.perimeter <= 600 and region.area <= 5000:\n",
    "        filtered_areas.append(region.area)\n",
    "\n",
    "# Sort to understand the range\n",
    "filtered_areas.sort()\n",
    "print(\"Filtered candidate areas:\", filtered_areas)\n"
   ],
   "id": "141a3395ecc1a843",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered candidate areas: [963.0, 1518.0, 2816.0, 3525.0]\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T15:48:39.003251Z",
     "start_time": "2025-05-19T15:48:37.683526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from skimage import io\n",
    "import glob\n",
    "\n",
    "# Step 1: Load and flatten images\n",
    "image_paths = sorted(glob.glob(\"exam_02502_E2024_data/screws/*.jpg\"))  # or .jpg, depending on format\n",
    "images = [io.imread(path, as_gray=True).flatten() for path in image_paths]\n",
    "X = np.array(images)\n",
    "\n",
    "# Step 2: Apply PCA\n",
    "pca = PCA()\n",
    "pca.fit(X)\n",
    "\n",
    "# Step 3: Compute cumulative explained variance\n",
    "cum_var = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "# Step 4: Find how many components explain at least 44%\n",
    "n_components = np.argmax(cum_var >= 0.44) + 1  # +1 because indices start at 0\n",
    "\n",
    "print(f\"Number of PCA components needed to explain at least 44% variance: {n_components}\")\n"
   ],
   "id": "c5ffca1568083bec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of PCA components needed to explain at least 44% variance: 3\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T15:50:12.825267Z",
     "start_time": "2025-05-19T15:50:11.374598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "# Load images and flatten them\n",
    "image_paths = sorted(glob.glob(\"exam_02502_E2024_data/screws/*.jpg\"))  # adjust the path and extension\n",
    "images = [io.imread(path, as_gray=True).flatten() for path in image_paths]\n",
    "X = np.array(images)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X)  # shape: [n_images, n_components]\n",
    "\n",
    "# Get PC1 values (first column)\n",
    "pc1_values = X_pca[:, 0]\n",
    "\n",
    "# Find indices of min and max PC1 projection\n",
    "min_index = np.argmin(pc1_values)\n",
    "max_index = np.argmax(pc1_values)\n",
    "\n",
    "# Load corresponding original images\n",
    "img_min = io.imread(image_paths[min_index])\n",
    "img_max = io.imread(image_paths[max_index])\n",
    "\n",
    "# Plot the two images\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img_min, cmap='gray')\n",
    "plt.title(f\"Min PC1 (Index {min_index})\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(img_max, cmap='gray')\n",
    "plt.title(f\"Max PC1 (Index {max_index})\")\n",
    "\n",
    "plt.suptitle(\"Images with Extreme PC1 Values\")\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "ee64ffb8192d82e8",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T15:51:20.032810Z",
     "start_time": "2025-05-19T15:51:15.850097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Load images and their filenames\n",
    "image_paths = sorted(glob.glob(\"exam_02502_E2024_data/screws/*.jpg\"))  # or .png depending on format\n",
    "filenames = [os.path.basename(p) for p in image_paths]\n",
    "images = [io.imread(p, as_gray=True).flatten() for p in image_paths]\n",
    "X = np.array(images)\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Find index of screws_007.jpg\n",
    "index_007 = filenames.index(\"screws_007.jpg\")\n",
    "\n",
    "# Plot all PCA projections and highlight screws_007.jpg\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c='gray', label=\"Other screws\")\n",
    "plt.scatter(X_pca[index_007, 0], X_pca[index_007, 1], c='red', label=\"screws_007.jpg\", edgecolors='black', s=100)\n",
    "plt.title(\"Screw projections on PCA space (PC1 vs PC2)\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.axis('equal')\n",
    "plt.show()\n"
   ],
   "id": "cf70ec80f86cab2a",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T15:52:39.195980Z",
     "start_time": "2025-05-19T15:52:33.987527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from skimage import io\n",
    "import glob\n",
    "import os\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# Load and flatten images\n",
    "image_paths = sorted(glob.glob(\"exam_02502_E2024_data/screws/*.jpg\"))  # or .png depending on format\n",
    "filenames = [os.path.basename(p) for p in image_paths]\n",
    "images = [io.imread(p, as_gray=True).flatten() for p in image_paths]\n",
    "X = np.array(images)\n",
    "\n",
    "# Project into PCA space\n",
    "pca = PCA(n_components=7)  # or use 2 for visualization only\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Compute pairwise distances\n",
    "dist_matrix = squareform(pdist(X_pca))\n",
    "\n",
    "# Set diagonal to infinity to ignore self-comparison\n",
    "np.fill_diagonal(dist_matrix, np.inf)\n",
    "\n",
    "# Find indices of the minimum distance\n",
    "i, j = np.unravel_index(np.argmin(dist_matrix), dist_matrix.shape)\n",
    "\n",
    "# Output the result\n",
    "print(f\"The two most similar photos in PCA space are:\")\n",
    "print(f\"{filenames[i]} and {filenames[j]}\")\n",
    "print(f\"Distance: {dist_matrix[i, j]:.4f}\")\n"
   ],
   "id": "84f339b1898234b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two most similar photos in PCA space are:\n",
      "screws_012.jpg and screws_016.jpg\n",
      "Distance: 3.3881\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T15:54:02.388345Z",
     "start_time": "2025-05-19T15:53:57.604132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from skimage import io\n",
    "import glob\n",
    "import os\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# Load and flatten images\n",
    "image_paths = sorted(glob.glob(\"exam_02502_E2024_data/screws/*.jpg\"))  # or .png depending on your data\n",
    "filenames = [os.path.basename(p) for p in image_paths]\n",
    "images = [io.imread(p, as_gray=True).flatten() for p in image_paths]\n",
    "X = np.array(images)\n",
    "\n",
    "# Step 1: Apply PCA using all components\n",
    "n_components = X.shape[0]  # 20 images → up to 20 components\n",
    "pca = PCA(n_components=n_components)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Step 2: Find indices of screws_007.jpg and screws_008.jpg\n",
    "index_007 = filenames.index(\"screws_007.jpg\")\n",
    "index_008 = filenames.index(\"screws_008.jpg\")\n",
    "\n",
    "# Step 3: Compute Euclidean distance in full PCA space\n",
    "distance = euclidean(X_pca[index_007], X_pca[index_008])\n",
    "print(f\"Distance between screws_007 and screws_008 in PCA space: {distance:.4f}\")\n"
   ],
   "id": "9ea351f85a7c6d8d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between screws_007 and screws_008 in PCA space: 47.3644\n"
     ]
    }
   ],
   "execution_count": 50
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
